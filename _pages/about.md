---
permalink: /
title: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

# üßë About me

I am currently a 2rd-Year Master student at [Tsinghua University](https://www.tsinghua.edu.cn/en/), under the guidance of [Prof. Haoqian Wang](https://www.sigs.tsinghua.edu.cn/whq/). I got B.Eng. degree in Robot Engineering at [South China University of Technology](https://www.scut.edu.cn/). 

Currently, I‚Äôm interested in 3D computer vision, specializing in ‚Äã‚Äãhuman-centric tasks such as digital avatar creation and 3D scene reconstruction, leveraging techniques including 3D Gaussian Splatting.‚Äã
 
More about me through [CV-cn](_pages/files/Eastbean_CV.pdf).


# üíª Experience

08/2024 ~ 03/2025, I was a research intern at the [IDEA](https://www.idea.edu.cn/).

<br>

# üìù Publications 
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ECCV 2024</div><img src='_pages/files/GS-W.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

<a href="https://arxiv.org/abs/2407.06984" style="font-size: 22px; color: #483D8B; text-decoration: none">**Category-level Object Detection, Pose Estimation and Reconstruction from Stereo Images**</a><br>
<span style="font-size: 18px;">**Chuanrui Zhang\*** , Yonggen Ling\*‚Ä†, Minglei Lu, Minghan Qin, Haoqian Wang‚Ä†</span><br>
<span style="font-size: 18px;">[**Website**](https://xingyoujun.github.io/coders)   [**Paper**](https://arxiv.org/abs/2407.06984)   [**Code**](#todo)</span>

<span style="font-size: 18px;">-  We present CODERS, a one-stage approach for Category-level Object Detection, pose Estimation and Reconstruction from Stereo images.</span>

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2025</div><img src='_pages/files/HRAvatar.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

<a href="https://arxiv.org/abs/2408.13770" style="font-size: 22px; color: #483D8B; text-decoration: none">**TranSplat: Generalizable 3D Gaussian Splatting from Sparse Multi-View Images with Transformers**</a><br>
<span style="font-size: 18px;">**Chuanrui Zhang\***, Yingshuang Zou\*, Zhuoling Li, Minmin Yi, Haoqian Wang‚Ä†</span><br>
<span style="font-size: 18px;">[**Website**](https://xingyoujun.github.io/transplat) [**Paper**](https://arxiv.org/abs/2408.13770)   [**Code**](https://github.com/xingyoujun/transplat)</span>

<span style="font-size: 18px;">-  We present TranSplat, a transformer-based approach for generalizable 3D gaussian splatting from sparse multi-view images.</span>

</div>
</div>

# üìÑ Preprint Papers
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Arxiv</div><img src='_pages/files/GUAVA.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

<a href="https://arxiv.org/abs/2304.01054" style="font-size: 22px; color: #483D8B; text-decoration: none">**VoxelFormer: Bird‚Äôs-Eye-View Feature Generation based on Dual-view Attention for Multi-view 3D Object Detection**</a><br>
<span style="font-size: 18px;">Zhuoling Li\*, **Chuanrui Zhang\***, Wei-Chiu Ma, Yipin Zhou, Linyan Huang, Haoqian Wang‚Ä†, SerNam Lim, Hengshuang Zhao‚Ä†</span><br>
<span style="font-size: 18px;">[**Paper**](https://arxiv.org/abs/2304.01054)   [**Code**](https://github.com/Lizhuoling/VoxelFormer-public)</span>

<span style="font-size: 18px;">-  We introduce Dual-View Attention, a more effecient cross attention for Multi-view 3D Object Detection.</span>

</div>
</div>

# üèÜ Honors and Awards

- Scholarship, Tsinghua University, 2024.
- Scholarship, South China University of Technology, 2019-2023.
